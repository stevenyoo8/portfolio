---
title: "Worksheet 16: k-Nearest Neighbors and other classifications"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
---

```{r global_options, include=FALSE}
# The following code is a basic setup of options for your document
# You won't have to edit it (unless you want to!)
knitr::opts_chunk$set(echo = TRUE, eval = TRUE,  
                      warning = FALSE, message = FALSE, 
                      fig.align = "center",
                      R.options = list(max.print = 100))

# Edit the file starting below
```

## 1. Set up

We will use many packages today! We've already used `tidyverse` and `plotROC` but let's install `caret`, `rpart`, `rpart.plot` and `randomForest`:

```{r, eval=FALSE}
# Install new packages (only needed once!)
install.packages("caret")
install.packages("rpart")
install.packages("rpart.plot")
```

```{r, message=FALSE}
# Load packages
library(tidyverse)
library(plotROC)
library(caret)
library(rpart)
library(rpart.plot)
```

Recall the `biopsy` dataset that contains information about tumor biopsy results. Nine features of the tumor were measured (on a 1-10 scale) as well as the `outcome` variable (malignant vs. benign).

```{r}
# Upload the data from GitHub
biopsy <- read_csv("https://raw.githubusercontent.com/laylaguyot/datasets/main//Biopsy.csv")

# Take a quick look
sample_n(size = 5, biopsy)
```

Our goal is to identify a tumor as malignant or benign based on some other features (variables) of a tumor.

## 2. k-Nearest Neighbors

Let's first consider the method of the k-Nearest Neighbor (kNN). This classifier determines the class of a data point by majority voting principle. If k is set to 5, the classes of 5 closest points are checked and the prediction is done according to the majority class.

### a. Fitting a model with 1 predictor

We can use the function `knn3` from the `caret` package to fit this model:

```{r}
# Consider the kNN classifier with k = 5
biopsy_kNN <- knn3(outcome ~ clump_thickness,
                data = biopsy, 
                k = 5) # number of neighbors
```

### b. Making predictions

We can use the classifier to find the proportion of the 5-nearest neighbors that have malignant outcomes with the `predict()` function:

```{r}
# Find the proportion of nearest neighbors with malignant outcomes
predict(biopsy_kNN, biopsy) %>% as.data.frame %>% head
```

The output shows two columns. Indeed, the `predict()` function provides a matrix object with 1 column representing the proportions of each `outcome` in the 5 nearest neighbors. The sum of these two columns is 1: we are particularly interested in the second column which indicates the probability of being malignant based on the 5 nearest neighbors. Let's use indexing to add these predictions to our data:

```{r}
biopsy %>%
  mutate(predictions = predict(biopsy_kNN, biopsy)[,2], # keep column 2
         predicted = ifelse(predictions > 0.5, "malignant","benign"))
```

#### **Try it! Find the true positive and true negative rates of our kNN model. Also build a ROC curve and find the value of the AUC. What do you think about the performance of this classifier?**

```{r}
# Write code here
biopsy %>%
  mutate(predictions = predict(biopsy_kNN, biopsy)[,2], # keep column 2
         predicted = ifelse(predictions > 0.5, "malignant","benign"),
         result = ifelse(predicted == outcome, TRUE, FALSE)) %>%
  group_by(outcome) %>%
  summarize(mean(result))

biopsy %>%
  mutate(predictions = predict(biopsy_kNN, biopsy))

# ROC
ROC <- biopsy %>%
  # Make predictions
  mutate(predictions = predict(biopsy_kNN, biopsy)[,2]) %>%
  ggplot() + 
  geom_roc(aes(d = outcome, m = predictions), n.cuts = 10)
ROC

calc_auc(ROC)
```

### c. Adding more predictors

Let's see how we improve the performance of our classifier if we consider one more predictor: `uniform_cell_size`. We will still consider the 5-nearest neighbors.

```{r}
# kNN with k = 5
biopsy_kNN <- knn3(outcome ~ clump_thickness + uniform_cell_size, 
                   data = biopsy, k = 5)
```

Has the performance improve based on the value of AUC?

```{r}
# Build new ROC curve
ROC <- ggplot(biopsy) + 
  geom_roc(aes(d = outcome, m = predict(biopsy_kNN, biopsy)[,2]), n.cuts = 10)
ROC # look at the warning message

# Value of AUC
calc_auc(ROC)
```

### d. Visualization of the decision boundary

We can visualize the decision boundary of our kNN classifer which separates predicted outcomes of malignant and benign tumors in our `biopsy` dataset:

```{r}
# Recall the classifier: kNN with k = 5 and two predictors
biopsy_kNN <- knn3(outcome ~ clump_thickness + uniform_cell_size, 
                   data = biopsy, k = 5)

# Make a grid (values for x and y) to layout the contour geom
grid <- data.frame(expand.grid(clump_thickness = seq(min(biopsy$clump_thickness),
                                            max(biopsy$clump_thickness),
                                            length.out = 100),
                               uniform_cell_size = seq(min(biopsy$uniform_cell_size),
                                      max(biopsy$uniform_cell_size),
                                      length.out = 100)))

# Use this grid to predict the outcome
grid %>% 
  # Make predictions for each value of the grid
  mutate(predictions = predict(biopsy_kNN, grid)[,2]) %>%
  # Layout the grid
  ggplot(aes(x = clump_thickness, y = uniform_cell_size)) +
   # Draw the decision boundary
  geom_contour(aes(z = predictions), breaks = 0.5) +
  # Points represent data from biopsy
  geom_point(data = biopsy, # add data from our dataset
             aes(x = clump_thickness, y = uniform_cell_size,
                 color = as.factor(outcome)), alpha = 0.2) + 
  # Clean up the tick marks
  scale_x_continuous(breaks = seq(1,10,1)) + 
  scale_y_continuous(breaks = seq(1,10,1)) +
  # Clean up the labels
  labs(color = "Outcome", x = "Clump thickness", y = "Uniform cell size")
```

Can you identify the false positive cases? false negative?

## 3. Decision trees

Another type of classifier is a decision tree. The decision tree comes up with some rules to split our data into groups in which we identify the majority of each class.

### a. Fitting a model with 1 predictor

Let's try to predict if a tumor should be considered malignant or not based on its value of clump thickness with a decision tree. We can use the function `rpart`:

```{r}
# Consider the decision tree classifier
biopsy_tree <- rpart(outcome ~ clump_thickness, # model
                    data = biopsy, # data
                    method = "class") # classification
```

We can visualize our tree with its corresponding rules with the function `rpart.plot`:

```{r}
# Visualize the decision tree
rpart.plot(biopsy_tree)
```

### b. Making predictions

Let's use this new classifier to find the proportion of the 5-nearest neighbors that have malignant outcomes with the `predict()` function:

```{r}
# Find the probability of a malignant outcome
predict(biopsy_tree, biopsy) %>% as.data.frame %>% head
```

Why does it make sense that we only have two possible values for that probability?

#### **Try it! Find the AUC of our decision tree. What do you think about the performance of this new classifier?**

```{r}
# Write code here
ROC <- biopsy %>%
  # Make predictions
  mutate(predictions = predict(biopsy_tree, biopsy)[, 2]) %>%
  ggplot() + 
  geom_roc(aes(d = outcome, m = predictions), n.cuts = 10)
ROC

# Value of AUC
calc_auc(ROC)

calc_auc(biopsy %>%
  # Make predictions
  mutate(predictions = predict(biopsy_tree, biopsy)[, 2]) %>%
  ggplot() + 
  geom_roc(aes(d = outcome, m = predictions), n.cuts = 10))
```

### c. Adding more predictors

Let's see how we improve the performance of our classifier if we consider an additional predictor: `uniform_cell_size`.

#### **Try it! Build another decision tree based on `clump_thickness` and `uniform_cell_size`. What rules are established by the tree to classify a tumor as malignant or benign? Has the performance of our model improved?**

```{r}
# Write code here
biopsy_tree <- rpart(outcome ~ clump_thickness + uniform_cell_size, # model
                    data = biopsy, # data
                    method = "class") # classification

rpart.plot(biopsy_tree)
```

### d. Visualization of the decision boundary

We can visualize the decision boundary of our decision tree classifer which separates predicted outcomes of malignant and benign tumors in the `biopsy` dataset.

#### **Try it! Build on the `grid` created earlier to display the decision boundary with `geom_contour()`. There is not much to change compared to the previous code!**

```{r}
# Write code here
biopsy_tree <- rpart(outcome ~ clump_thickness + uniform_cell_size, # model
                    data = biopsy, # data
                    method = "class") # classification

# Make a grid (values for x and y) to layout the contour geom
grid <- data.frame(expand.grid(clump_thickness = seq(min(biopsy$clump_thickness),
                                            max(biopsy$clump_thickness),
                                            length.out = 100),
                               uniform_cell_size = seq(min(biopsy$uniform_cell_size),
                                      max(biopsy$uniform_cell_size),
                                      length.out = 100)))

# Use this grid to predict the outcome
grid %>% 
  # Make predictions for each value of the grid
  mutate(predictions = predict(biopsy_tree, grid)[,2]) %>%
  # Layout the grid
  ggplot(aes(x = clump_thickness, y = uniform_cell_size)) +
   # Draw the decision boundary
  geom_contour(aes(z = predictions), breaks = 0.5) +
  # Points represent data from biopsy
  geom_point(data = biopsy, # add data from our dataset
             aes(x = clump_thickness, y = uniform_cell_size,
                 color = as.factor(outcome)), alpha = 0.2) + 
  # Clean up the tick marks
  scale_x_continuous(breaks = seq(1,10,1)) + 
  scale_y_continuous(breaks = seq(1,10,1)) +
  # Clean up the labels
  labs(color = "Outcome", x = "Clump thickness", y = "Uniform cell size")
```

## 4. Random forest

A random forest is what we call an ensemble algorithm because it aggregates different classifiers (here, many decision trees). Each tree will consider a different subset of the data and come up with a decision for classifying a tumor as either malignant or benign and the random forest will consider the most common outcome over all the trees. 

We need the `randomForest` package which is not available for our R version... we have learned enough classifiers for this course anyway :)

## 5. Comparing classifiers

Depending on our data, some classifiers might perform better than others. There is not a single best algorithm. But what classifier (logistic regression, kNN, decision tree) works best for `biopsy` if we consider all potential predictors?

#### **Try it! Let's compare the three classifiers (logistic regression, kNN, decision tree) considering all potential predictors in `biopsy`. Fit the three models with all predictors using `~ .`. Visualize the ROC curve of each classifier on the same plot. Note: the predict() function has a different syntax depending on which model we use. It might be a good idea to add some color to differentiate the models. Which classifier seem to perform better? worse?** 

```{r}
# Logistic regression
biopsy_log <- glm(outcome ~ ., data = biopsy %>%
                    mutate(outcome = ifelse(outcome == "benign", 0, 1)), 
                  family = "binomial")

# kNN
biopsy_kNN <- knn3(outcome ~ ., data = biopsy, k = 5)

# Decision tree
biopsy_tree <- rpart(outcome ~ ., data = biopsy, method = "class") 

# ROC curves
ggplot(biopsy) + 
  geom_roc(aes(d = outcome, m = predict(biopsy_log, type = "response")), n.cuts = 0, color = "blue") +
  geom_roc(aes(d = outcome, m = predict(biopsy_kNN, biopsy)[,2]), n.cuts = 0, color = "orange") +
  geom_roc(aes(d = outcome, m = predict(biopsy_tree, biopsy)[,2]), n.cuts = 0) +
  labs(caption = "Blue = Logistic Regression, Orange = kNN, Black = Decistion tree") +
  xlim(0,0.25) # "zoom" on the top left corner

```
